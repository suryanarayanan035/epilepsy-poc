{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D,LSTM,BatchNormalization,Dropout,MaxPool2D,Flatten,Dense,Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.data import Dataset\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_layers = [\n",
    "    \n",
    "    Conv2D(16,(3,3),input_shape=(15,1025,151),activation=\"relu\",name=\"Convolution_Layer_1\"),\n",
    "    MaxPool2D((2,2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32,(2,2),activation=\"relu\",name=\"Convolution_Layer_2\"),\n",
    "    MaxPool2D((2,2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Conv2D(64,(2,2),activation=\"relu\",name=\"Convolution_Layer_3\"),\n",
    "    BatchNormalization(),\n",
    "    Reshape((128,127))\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "      \n",
    "    LSTM(128),\n",
    "    Dropout(0.5),\n",
    "    Reshape((128,1)),\n",
    "    LSTM(128),\n",
    "    Dense(30,activation=\"relu\"),\n",
    "    Dense(1,activation=\"sigmoid\"),\n",
    "#     Reshape((1,2))\n",
    "    \n",
    "]\n",
    "full_layers = [layer for layer in feature_extraction_layers]\n",
    "full_layers+= [layer for layer in classification_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(full_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Convolution_Layer_1 (Conv2D) (None, 13, 1023, 16)      21760     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 511, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 511, 16)        64        \n",
      "_________________________________________________________________\n",
      "Convolution_Layer_2 (Conv2D) (None, 5, 510, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 255, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2, 255, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 255, 32)        0         \n",
      "_________________________________________________________________\n",
      "Convolution_Layer_3 (Conv2D) (None, 1, 254, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1, 254, 64)        256       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 128, 127)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               131072    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 128, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 234,077\n",
      "Trainable params: 233,853\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(folder,csv_file):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    with open(folder+csv_file) as csv_file:\n",
    "        reader =  csv.reader(csv_file,delimiter=\",\")\n",
    "        for row in reader:\n",
    "            features.append(np.load(folder+row[0]))\n",
    "            labels.append(float(row[1]))\n",
    "    return features,labels\n",
    "\n",
    "    \n",
    "def prepare_dataset(folder,csv_file):\n",
    "    reshaped_features= []\n",
    "    features,labels= create_dataset(folder,csv_file)\n",
    "    for feature in features:\n",
    "        reshaped_features.append(feature.reshape(1,15,1025,151))\n",
    "    reshaped_features=np.array(reshaped_features)\n",
    "    labels = np.array(labels)\n",
    "    labels=labels.reshape(-1,1)\n",
    "#     labels = tf.one_hot(labels,2)\n",
    "    dataset = Dataset.from_tensor_slices((reshaped_features,labels))\n",
    "    dataset = dataset.repeat(40)\n",
    "    return dataset,reshaped_features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,reshaped_features,labels = prepare_dataset(\"./training-preprocessed/\",\"training-dataset.csv\")\n",
    "# print(labels)\n",
    "validation_dataset,validation_features,_validation_labels = prepare_dataset(\"./preprocessed-validation-data/\",\"validation-dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1129/2480 [============>.................] - ETA: 2:46 - loss: 0.6446 - accuracy: 0.7836"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=tf.keras.optimizers.Adam(0.001),metrics=[\"accuracy\"])\n",
    "model.fit(dataset,epochs=10,validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './training-preprocessed/Patient_1_preictal_segment_0002_21.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bad9ee5905be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./training-preprocessed/Patient_1_preictal_segment_0002_21.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1025\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m151\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './training-preprocessed/Patient_1_preictal_segment_0002_21.npy'"
     ]
    }
   ],
   "source": [
    "test=np.load(\"./training-preprocessed/Patient_1_preictal_segment_0002_21.npy\")\n",
    "result=model.predict(test.reshape(1,15,1025,151))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6268092]]\n"
     ]
    }
   ],
   "source": [
    "test=np.load(\"./training-preprocessed/Patient_1_interictal_segment_0001_1.npy\")\n",
    "result=model.predict(test.reshape(1,15,1025,151))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
