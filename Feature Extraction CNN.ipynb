{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import InputLayer,Conv2D,BatchNormalization,MaxPool2D,Dropout,Flatten,LSTM,Dense,Reshape\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_layers = [\n",
    "    InputLayer(input_shape=(15,1025,151),name=\"Input Layer\",batch_size=1),\n",
    "    Conv2D(filters=32,kernel_size=(5,5),activation=\"relu\",name=\"Convolution_Layer_1\"),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"Max_Pool_1\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(rate=0.4),\n",
    "    Conv2D(filters=64,kernel_size=(2,2),activation=\"relu\",name=\"Convolution_Layer_2\"),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"Max_Pool_2\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=128,kernel_size=(1,1),activation=\"relu\",name=\"Convolution_Layer_3\"),\n",
    "    Flatten(),\n",
    "    Reshape((128,508)),\n",
    "    LSTM(128,name=\"LSTM_1\"),\n",
    "    Reshape((128,1)),\n",
    "    LSTM(127,name=\"LSTM_2\"),\n",
    "    Dropout(rate=0.4),\n",
    "    Dense(30,activation=\"relu\"),\n",
    "    Dense(4),\n",
    "    Reshape((2,2))\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_layers = [\n",
    "    InputLayer(input_shape=(15,1025,151),name=\"Input Layer\",batch_size=1),\n",
    "    Conv2D(filters=32,kernel_size=(5,5),activation=\"relu\",name=\"Convolution_Layer_1\"),\n",
    "    MaxPool2D(pool_size=(2,2),name=\"Max_Pool_1\"),\n",
    "    BatchNormalization(),\n",
    "    Reshape((64,1275)),\n",
    "    LSTM(64,name=\"LSTM_1\"),\n",
    "    Reshape((64,1)),\n",
    "    LSTM(64,name=\"LSTM_2\"),\n",
    "    Dropout(rate=0.4),\n",
    "    Dense(30,activation=\"relu\"),\n",
    "    Dense(4),\n",
    "    Reshape((2,2))\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model = Sequential(feature_extraction_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model.compile(optimizer=tf.keras.optimizers.Adam(0.00001)\n",
    "                                 ,metrics=[\"accuracy\"] ,loss=tf.keras.losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Convolution_Layer_1 (Conv2D) (1, 11, 1021, 32)         120832    \n",
      "_________________________________________________________________\n",
      "Max_Pool_1 (MaxPooling2D)    (1, 5, 510, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (1, 5, 510, 32)           128       \n",
      "_________________________________________________________________\n",
      "reshape_14 (Reshape)         (1, 64, 1275)             0         \n",
      "_________________________________________________________________\n",
      "LSTM_1 (LSTM)                (1, 64)                   343040    \n",
      "_________________________________________________________________\n",
      "reshape_15 (Reshape)         (1, 64, 1)                0         \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (1, 64)                   16896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (1, 64)                   0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 30)                   1950      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (1, 4)                    124       \n",
      "_________________________________________________________________\n",
      "reshape_16 (Reshape)         (1, 2, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 482,970\n",
      "Trainable params: 482,906\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extraction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    features = []\n",
    "    labels=[]\n",
    "    training_folder=\"./training/\"\n",
    "    with open(\"./training/dataset.csv\",\"r\") as csv_file:\n",
    "        file = csv.reader(csv_file)\n",
    "        for row in file:\n",
    "            features.append(np.reshape(np.load(training_folder+row[0]),(15,1025,151)))\n",
    "            labels.append(np.array([int(row[1]),int(row[2])]))\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    labels = tf.keras.utils.to_categorical(labels,num_classes=2)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "    dataset = dataset.repeat(60)\n",
    "    dataset = dataset.shuffle(4)\n",
    "    dataset = dataset.batch(15)\n",
    "    dataset = dataset.as_numpy_iterator()\n",
    "    return features,labels,dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,labels,dataset = create_dataset()\n",
    "#print(\"Labels without one hot encoding\",labels)\n",
    "#labels = tf.keras.utils.to_categorical(labels,num_classes=2)\n",
    "#print(\"Labels\",labels)\n",
    "feature_extraction_model.fit(dataset,epochs=30,batch_size=15,steps_per_epoch=23)\n",
    "# data = np.reshape(data,(1,15,1025,151))\n",
    "# prediction = feature_extraction_model.fit(data)\n",
    "# prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=feature_extraction_model.predict(np.array(np.reshape(np.load(\"./training/\"+\"Patient_1_interictal_segment_0004_1.npy\"),(1,15,1025,151))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[[ 0.7400652  -0.62076694]\n",
      "  [-0.02251145 -0.00233709]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
